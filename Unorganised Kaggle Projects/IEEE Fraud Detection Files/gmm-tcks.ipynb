{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, os\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import svm, neighbors, linear_model, neural_network\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from tqdm import tqdm_notebook\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from vecstack import stacking \n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import sympy\n",
    "from sklearn.covariance import EmpiricalCovariance\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.covariance import GraphicalLasso\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_cov(x,y):\n",
    "    model = GraphicalLasso()\n",
    "    ones = (y==1).astype(bool)\n",
    "    x2 = x[ones]\n",
    "    model.fit(x2)\n",
    "    p1 = model.precision_\n",
    "    m1 = model.location_\n",
    "    \n",
    "    onesb = (y==0).astype(bool)\n",
    "    x2b = x[onesb]\n",
    "    model.fit(x2b)\n",
    "    p2 = model.precision_\n",
    "    m2 = model.location_\n",
    "    \n",
    "    ms = np.stack([m1,m2])\n",
    "    ps = np.stack([p1,p2])\n",
    "    return ms,ps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')\n",
    "\n",
    "\n",
    "cols = [c for c in train.columns if c not in ['id', 'target']]\n",
    "cols.remove('wheezy-copper-turtle-magic')\n",
    "oof = np.zeros(len(train))\n",
    "preds = np.zeros(len(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [42:18<00:00,  5.18s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# BUILD 512 SEPARATE MODELS\n",
    "for i in tqdm(range(512)):\n",
    "    # ONLY TRAIN WITH DATA WHERE WHEEZY EQUALS I\n",
    "    train2 = train[train['wheezy-copper-turtle-magic']==i]\n",
    "    test2 = test[test['wheezy-copper-turtle-magic']==i]\n",
    "    idx1 = train2.index; idx2 = test2.index\n",
    "    train2.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    # FEATURE SELECTION (USE APPROX 40 OF 255 FEATURES)\n",
    "    sel = VarianceThreshold(threshold=1.5).fit(train2[cols])\n",
    "    train3 = sel.transform(train2[cols])\n",
    "    test3 = sel.transform(test2[cols])\n",
    "    \n",
    "    # STRATIFIED K-FOLD\n",
    "    skf = StratifiedKFold(n_splits=24, random_state=42, shuffle=True)\n",
    "    for train_index, test_index in skf.split(train3, train2['target']):\n",
    "        \n",
    "        # MODEL AND PREDICT WITH QDA\n",
    "        ms, ps = get_mean_cov(train3[train_index,:],train2.loc[train_index]['target'].values)\n",
    "        gm = GaussianMixture(n_components=2, init_params='random', covariance_type='full', tol=0.001,reg_covar=0.001, max_iter=100, n_init=1,means_init=ms, precisions_init=ps, verbose=0, verbose_interval=10000)\n",
    "        gm.fit(np.concatenate([train3[train_index,:],test3],axis = 0))\n",
    "        oof[idx1[test_index]] = gm.predict_proba(train3[test_index,:])[:,0]\n",
    "        preds[idx2] += gm.predict_proba(test3)[:,0] / skf.n_splits\n",
    "        \n",
    "    #if i%64==0: print(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QDA scores CV = 0.96906\n"
     ]
    }
   ],
   "source": [
    "# PRINT CV AUC\n",
    "auc = roc_auc_score(train['target'],oof)\n",
    "print('QDA scores CV =',round(auc,5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.038074493408203125\n"
     ]
    }
   ],
   "source": [
    "print(len(train.loc[ abs(train['target']-oof)>0.9,'target'])/len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(oof,bins=100)\n",
    "plt.title('predictions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flip started\n",
      "flip completed\n"
     ]
    }
   ],
   "source": [
    "# INITIALIZE VARIABLES\n",
    "print('flip started')\n",
    "test['target'] = preds\n",
    "\n",
    "# flip y\n",
    "train_new = train.copy()\n",
    "train.loc[oof > 0.9, 'target'] = 1\n",
    "train.loc[oof < 0.1, 'target'] = 0\n",
    "\n",
    "\n",
    "print('flip completed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_svnu = np.zeros(len(train)) \n",
    "pred_te_svnu = np.zeros(len(test))\n",
    "oof_svc = np.zeros(len(train)) \n",
    "pred_te_svc = np.zeros(len(test))\n",
    "oof_knn = np.zeros(len(train)) \n",
    "pred_te_knn = np.zeros(len(test))\n",
    "oof_lr = np.zeros(len(train)) \n",
    "pred_te_lr = np.zeros(len(test))\n",
    "oof_mlp = np.zeros(len(train)) \n",
    "pred_te_mlp = np.zeros(len(test))\n",
    "oof_lgb = np.zeros(len(train)) \n",
    "pred_te_lgb = np.zeros(len(test))\n",
    "oof_xgb = np.zeros(len(train)) \n",
    "pred_te_xgb = np.zeros(len(test))\n",
    "oof_qda = np.zeros(len(train)) \n",
    "pred_te_qda = np.zeros(len(test))\n",
    "\n",
    "oof_svnu2 = np.zeros(len(train)) \n",
    "pred_te_svnu2 = np.zeros(len(test))\n",
    "oof_svc2 = np.zeros(len(train)) \n",
    "pred_te_svc2 = np.zeros(len(test))\n",
    "oof_knn2 = np.zeros(len(train)) \n",
    "pred_te_knn2 = np.zeros(len(test))\n",
    "oof_lr2 = np.zeros(len(train)) \n",
    "pred_te_lr2 = np.zeros(len(test))\n",
    "oof_mlp2 = np.zeros(len(train)) \n",
    "pred_te_mlp2 = np.zeros(len(test))\n",
    "oof_lgb2 = np.zeros(len(train)) \n",
    "pred_te_lgb2 = np.zeros(len(test))\n",
    "oof_xgb2 = np.zeros(len(train)) \n",
    "pred_te_xgb2 = np.zeros(len(test))\n",
    "oof_qda2 = np.zeros(len(train)) \n",
    "pred_te_qda2 = np.zeros(len(test))\n",
    "\n",
    "oof_lr3 = np.zeros(len(train)) \n",
    "pred_te_lr3 = np.zeros(len(test))\n",
    "oof_gm = np.zeros(len(train)) \n",
    "pred_te_gm = np.zeros(len(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "64\n",
      "128\n",
      "192\n",
      "256\n",
      "320\n",
      "384\n",
      "448\n"
     ]
    }
   ],
   "source": [
    "cols = [c for c in train.columns if c not in ['id', 'target', 'wheezy-copper-turtle-magic']]\n",
    "\n",
    "for i in range(512):\n",
    "    train2_o = train[train['wheezy-copper-turtle-magic']==i]\n",
    "    test2 = test[test['wheezy-copper-turtle-magic']==i]\n",
    "    train2 = train2_o.copy()\n",
    "    idx1 = train2_o.index; idx2 = test2.index\n",
    "    #train2.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    # ADD PSEUDO LABEL DATA\n",
    "    test2p = test2[ (test2['target']<=0.01) | (test2['target']>=0.99) ].copy()\n",
    "    test2p.loc[ test2p['target']>=0.5, 'target' ] = 1\n",
    "    test2p.loc[ test2p['target']<0.5, 'target' ] = 0 \n",
    "    train2 = pd.concat([train2,test2p],axis=0)\n",
    "    train2.reset_index(drop=True,inplace=True)\n",
    "\n",
    "    data = pd.concat([pd.DataFrame(train2_o[cols]), pd.DataFrame(test2[cols])])\n",
    "    pca = PCA(svd_solver='full',n_components='mle')\n",
    "    ss = StandardScaler()\n",
    "    pca.fit(data[cols])\n",
    "    data2 = pca.transform(data[cols])\n",
    "    train3_o = pca.transform(train2_o[cols])\n",
    "    train3 = pca.transform(train2[cols])\n",
    "    test3 = pca.transform(test2[cols])\n",
    "    ss.fit(data2)\n",
    "    train3 = ss.transform(train3)\n",
    "    train3_o = ss.transform(train3_o)\n",
    "    test3 = ss.transform(test3)\n",
    "    #data2 = StandardScaler().fit_transform(PCA(svd_solver='full',n_components='mle').fit_transform(data[cols]))\n",
    "    #train3 = data2[:train2.shape[0]]; test3 = data2[train2.shape[0]:]\n",
    "    pca = VarianceThreshold(threshold=1.5)\n",
    "    ss = StandardScaler()\n",
    "    pca.fit(data[cols])\n",
    "    data3 = pca.transform(data[cols])\n",
    "    train4_o = pca.transform(train2_o[cols])\n",
    "    train4 = pca.transform(train2[cols])\n",
    "    test4 = pca.transform(test2[cols])\n",
    "    ss.fit(data3)\n",
    "    train4 = ss.transform(train4)\n",
    "    train4_o = ss.transform(train4_o)\n",
    "    test4 = ss.transform(test4)\n",
    "    \n",
    "    data4 = ss.transform(data3)\n",
    "    poly = PolynomialFeatures(degree=2)\n",
    "    poly.fit(data4)\n",
    "    train5_o = poly.transform(train4_o)\n",
    "    train5 = poly.transform(train4)\n",
    "    test5 = poly.transform(test4)\n",
    "    \n",
    "    del data, data2, data3, data4\n",
    "    \n",
    "    # STRATIFIED K FOLD (Using splits=25 scores 0.002 better but is slower)\n",
    "    skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    for train_index, test_index in skf.split(train2, train2['target']):\n",
    "        \n",
    "        test_index = test_index[ test_index<len(train2_o) ] # ignore psuedo in oof\n",
    "\n",
    "        clf = NuSVC(probability=True, kernel='poly', degree=4, gamma='auto', random_state=4, nu=0.59, coef0=0.053)\n",
    "        clf.fit(train3[train_index,:],train2.loc[train_index]['target'])\n",
    "        oof_svnu[idx1[test_index]] = clf.predict_proba(train3_o[test_index,:])[:,1]\n",
    "        pred_te_svnu[idx2] += clf.predict_proba(test3)[:,1] / skf.n_splits\n",
    "        \n",
    "        clf = neighbors.KNeighborsClassifier(n_neighbors=17, p=2.9, n_jobs=-1)\n",
    "        clf.fit(train3[train_index,:],train2.loc[train_index]['target'])\n",
    "        oof_knn[idx1[test_index]] = clf.predict_proba(train3_o[test_index,:])[:,1]\n",
    "        pred_te_knn[idx2] += clf.predict_proba(test3)[:,1] / skf.n_splits\n",
    "        \n",
    "        clf = linear_model.LogisticRegression(solver='saga',penalty='l1',C=0.1, n_jobs=-1)\n",
    "        clf.fit(train3[train_index,:],train2.loc[train_index]['target'])\n",
    "        oof_lr[idx1[test_index]] = clf.predict_proba(train3_o[test_index,:])[:,1]\n",
    "        pred_te_lr[idx2] += clf.predict_proba(test3)[:,1] / skf.n_splits\n",
    "        \n",
    "        clf = neural_network.MLPClassifier(random_state=3,  activation='relu', solver='lbfgs', tol=1e-06, hidden_layer_sizes=(250, ))\n",
    "        clf.fit(train3[train_index,:],train2.loc[train_index]['target'])\n",
    "        oof_mlp[idx1[test_index]] = clf.predict_proba(train3_o[test_index,:])[:,1]\n",
    "        pred_te_mlp[idx2] += clf.predict_proba(test3)[:,1] / skf.n_splits\n",
    "        \n",
    "        clf = svm.SVC(probability=True, kernel='poly', degree=4, gamma='auto', random_state=42)\n",
    "        clf.fit(train3[train_index,:],train2.loc[train_index]['target'])\n",
    "        oof_svc[idx1[test_index]] = clf.predict_proba(train3_o[test_index,:])[:,1]\n",
    "        pred_te_svc[idx2] += clf.predict_proba(test3)[:,1] / skf.n_splits\n",
    "        \n",
    "        clf = LGBMClassifier(random_state=42)\n",
    "        clf.fit(train3[train_index,:],train2.loc[train_index]['target'])\n",
    "        oof_lgb[idx1[test_index]] = clf.predict_proba(train3_o[test_index,:])[:,1]\n",
    "        pred_te_lgb[idx2] += clf.predict_proba(test3)[:,1] / skf.n_splits\n",
    "        \n",
    "        clf = XGBClassifier(random_state=42)\n",
    "        clf.fit(train3[train_index,:],train2.loc[train_index]['target'])\n",
    "        oof_xgb[idx1[test_index]] = clf.predict_proba(train3_o[test_index,:])[:,1]\n",
    "        pred_te_xgb[idx2] += clf.predict_proba(test3)[:,1] / skf.n_splits\n",
    "        \n",
    "        clf = QuadraticDiscriminantAnalysis(0.1)\n",
    "        clf.fit(train3[train_index,:],train2.loc[train_index]['target'])\n",
    "        oof_qda[idx1[test_index]] = clf.predict_proba(train3_o[test_index,:])[:,1]\n",
    "        pred_te_qda[idx2] += clf.predict_proba(test3)[:,1] / skf.n_splits\n",
    "        \n",
    "        ###############################################################################\n",
    "        clf = NuSVC(probability=True, kernel='poly', degree=4, gamma='auto', random_state=4, nu=0.59, coef0=0.053)\n",
    "        clf.fit(train4[train_index,:],train2.loc[train_index]['target'])\n",
    "        oof_svnu2[idx1[test_index]] = clf.predict_proba(train4_o[test_index,:])[:,1]\n",
    "        pred_te_svnu2[idx2] += clf.predict_proba(test4)[:,1] / skf.n_splits\n",
    "        \n",
    "        clf = neighbors.KNeighborsClassifier(n_neighbors=17, p=2.9, n_jobs=-1)\n",
    "        clf.fit(train4[train_index,:],train2.loc[train_index]['target'])\n",
    "        oof_knn2[idx1[test_index]] = clf.predict_proba(train4_o[test_index,:])[:,1]\n",
    "        pred_te_knn2[idx2] += clf.predict_proba(test4)[:,1] / skf.n_splits\n",
    "        \n",
    "        clf = linear_model.LogisticRegression(solver='saga',penalty='l1',C=0.1, n_jobs=-1)\n",
    "        clf.fit(train4[train_index,:],train2.loc[train_index]['target'])\n",
    "        oof_lr2[idx1[test_index]] = clf.predict_proba(train4_o[test_index,:])[:,1]\n",
    "        pred_te_lr2[idx2] += clf.predict_proba(test4)[:,1] / skf.n_splits\n",
    "        \n",
    "        clf = neural_network.MLPClassifier(random_state=3,  activation='relu', solver='lbfgs', tol=1e-06, hidden_layer_sizes=(250, ))\n",
    "        clf.fit(train4[train_index,:],train2.loc[train_index]['target'])\n",
    "        oof_mlp2[idx1[test_index]] = clf.predict_proba(train4_o[test_index,:])[:,1]\n",
    "        pred_te_mlp2[idx2] += clf.predict_proba(test4)[:,1] / skf.n_splits\n",
    "        \n",
    "        clf = svm.SVC(probability=True, kernel='poly', degree=4, gamma='auto', random_state=42)\n",
    "        clf.fit(train4[train_index,:],train2.loc[train_index]['target'])\n",
    "        oof_svc2[idx1[test_index]] = clf.predict_proba(train4_o[test_index,:])[:,1]\n",
    "        pred_te_svc2[idx2] += clf.predict_proba(test4)[:,1] / skf.n_splits\n",
    "        \n",
    "        clf = LGBMClassifier(random_state=42)\n",
    "        clf.fit(train4[train_index,:],train2.loc[train_index]['target'])\n",
    "        oof_lgb2[idx1[test_index]] = clf.predict_proba(train4_o[test_index,:])[:,1]\n",
    "        pred_te_lgb2[idx2] += clf.predict_proba(test4)[:,1] / skf.n_splits\n",
    "        \n",
    "        clf = XGBClassifier(random_state=42)\n",
    "        clf.fit(train4[train_index,:],train2.loc[train_index]['target'])\n",
    "        oof_xgb2[idx1[test_index]] = clf.predict_proba(train4_o[test_index,:])[:,1]\n",
    "        pred_te_xgb2[idx2] += clf.predict_proba(test4)[:,1] / skf.n_splits\n",
    "        \n",
    "        clf = QuadraticDiscriminantAnalysis(0.1)\n",
    "        clf.fit(train4[train_index,:],train2.loc[train_index]['target'])\n",
    "        oof_qda2[idx1[test_index]] = clf.predict_proba(train4_o[test_index,:])[:,1]\n",
    "        pred_te_qda2[idx2] += clf.predict_proba(test4)[:,1] / skf.n_splits\n",
    "        \n",
    "        #####################################################################################\n",
    "        \n",
    "        clf = linear_model.LogisticRegression(solver='saga',penalty='l2',C=0.01,tol=0.001, n_jobs=-1)\n",
    "        clf.fit(train5[train_index,:],train2.loc[train_index]['target'])\n",
    "        oof_lr3[idx1[test_index]] = clf.predict_proba(train5_o[test_index,:])[:,1]\n",
    "        pred_te_lr3[idx2] += clf.predict_proba(test5)[:,1] / skf.n_splits\n",
    "        \n",
    "        ms, ps = get_mean_cov(train4[train_index,:],train2.loc[train_index]['target'].values)\n",
    "        clf = GaussianMixture(n_components=2, init_params='random', covariance_type='full', tol=0.001,reg_covar=0.001, max_iter=100, n_init=1,means_init=ms, precisions_init=ps)\n",
    "        clf.fit(np.concatenate([train4[train_index,:],test4],axis = 0))\n",
    "        oof_gm[idx1[test_index]] = clf.predict_proba(train4_o[test_index,:])[:,0]\n",
    "        pred_te_gm[idx2] += clf.predict_proba(test4)[:,0] / skf.n_splits\n",
    "    \n",
    "    if i%64==0: print(i)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.8120002202091721\n",
      "knn 0.9356827444636515\n",
      "svc 0.9633992030339213\n",
      "svcnu 0.9683767388877126\n",
      "mlp 0.9427105623515943\n",
      "lgb 0.8767298150863782\n",
      "xgb 0.8515156946160211\n",
      "qda 0.9684132341380736\n",
      "lr 0.8115682569372643\n",
      "knn 0.9359205211186393\n",
      "svc 0.9548242390588377\n",
      "svcnu 0.9640175351375389\n",
      "mlp 0.9392337878509899\n",
      "lgb 0.8702564492334319\n",
      "xgb 0.8443727983255934\n",
      "qda 0.9685846570438701\n",
      "lr 0.9623859780878754\n",
      "gm 0.9673468853483506\n"
     ]
    }
   ],
   "source": [
    "print('lr', roc_auc_score(train_new['target'], oof_lr))\n",
    "print('knn', roc_auc_score(train_new['target'], oof_knn))\n",
    "print('svc', roc_auc_score(train_new['target'], oof_svc))\n",
    "print('svcnu', roc_auc_score(train_new['target'], oof_svnu))\n",
    "print('mlp', roc_auc_score(train_new['target'], oof_mlp))\n",
    "print('lgb', roc_auc_score(train_new['target'], oof_lgb))\n",
    "print('xgb', roc_auc_score(train_new['target'], oof_xgb))\n",
    "print('qda', roc_auc_score(train_new['target'], oof_qda))\n",
    "\n",
    "print('lr', roc_auc_score(train_new['target'], oof_lr2))\n",
    "print('knn', roc_auc_score(train_new['target'], oof_knn2))\n",
    "print('svc', roc_auc_score(train_new['target'], oof_svc2))\n",
    "print('svcnu', roc_auc_score(train_new['target'], oof_svnu2))\n",
    "print('mlp', roc_auc_score(train_new['target'], oof_mlp2))\n",
    "print('lgb', roc_auc_score(train_new['target'], oof_lgb2))\n",
    "print('xgb', roc_auc_score(train_new['target'], oof_xgb2))\n",
    "print('qda', roc_auc_score(train_new['target'], oof_qda2))\n",
    "\n",
    "\n",
    "print('lr', roc_auc_score(train_new['target'], oof_lr3))\n",
    "print('gm', roc_auc_score(train_new['target'], oof_gm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(262144, 273) (131073, 273)\n"
     ]
    }
   ],
   "source": [
    "tr = train[cols].copy()\n",
    "te = test[cols].copy()\n",
    "\n",
    "tr['oof_svnu'] = oof_svnu\n",
    "te['oof_svnu'] = pred_te_svnu\n",
    "tr['oof_svc'] = oof_svc\n",
    "te['oof_svc'] = pred_te_svc\n",
    "tr['oof_knn'] = oof_knn\n",
    "te['oof_knn'] = pred_te_knn\n",
    "tr['oof_mlp'] = oof_mlp\n",
    "te['oof_mlp'] = pred_te_mlp\n",
    "tr['oof_lr'] = oof_lr\n",
    "te['oof_lr'] = pred_te_lr\n",
    "tr['oof_lgb'] = oof_lgb\n",
    "te['oof_lgb'] = pred_te_lgb\n",
    "tr['oof_xgb'] = oof_xgb\n",
    "te['oof_xgb'] = pred_te_xgb\n",
    "tr['oof_qda'] = oof_qda\n",
    "te['oof_qda'] = pred_te_qda\n",
    "\n",
    "tr['oof_svnu2'] = oof_svnu2\n",
    "te['oof_svnu2'] = pred_te_svnu2\n",
    "tr['oof_svc2'] = oof_svc2\n",
    "te['oof_svc2'] = pred_te_svc2\n",
    "tr['oof_knn2'] = oof_knn2\n",
    "te['oof_knn2'] = pred_te_knn2\n",
    "tr['oof_mlp2'] = oof_mlp2\n",
    "te['oof_mlp2'] = pred_te_mlp2\n",
    "tr['oof_lr2'] = oof_lr2\n",
    "te['oof_lr2'] = pred_te_lr2\n",
    "tr['oof_lgb2'] = oof_lgb2\n",
    "te['oof_lgb2'] = pred_te_lgb2\n",
    "tr['oof_xgb2'] = oof_xgb2\n",
    "te['oof_xgb2'] = pred_te_xgb2\n",
    "tr['oof_qda2'] = oof_qda2\n",
    "te['oof_qda2'] = pred_te_qda2\n",
    "\n",
    "tr['oof_lr3'] = oof_lr3\n",
    "te['oof_lr3'] = pred_te_lr3\n",
    "\n",
    "tr['oof_gm'] = oof_gm\n",
    "te['oof_gm'] = pred_te_gm\n",
    "\n",
    "print(tr.shape, te.shape)\n",
    "\n",
    "tr = tr.values\n",
    "te = te.values\n",
    "\n",
    "del oof_svnu, oof_svc, oof_knn, oof_mlp, oof_lr, oof_lgb, oof_xgb, oof_qda, oof_svnu2, oof_svc2, oof_knn2, oof_mlp2, oof_lr2, oof_lgb2, oof_xgb2, oof_qda2, oof_lr3, oof_gm\n",
    "del pred_te_svnu, pred_te_svc, pred_te_knn, pred_te_mlp, pred_te_lr, pred_te_lgb, pred_te_xgb, pred_te_qda, pred_te_svnu2, pred_te_svc2, pred_te_knn2, pred_te_mlp2, pred_te_lr2, pred_te_lgb2, pred_te_xgb2, pred_te_qda2, pred_te_lr3, pred_te_gm\n",
    "del train3, train4, test3, test4, train2, test2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level 2 started\n"
     ]
    }
   ],
   "source": [
    "models = [ \n",
    "    GaussianNB(),\n",
    "    LogisticRegression(random_state=42, n_jobs=-1),\n",
    "    ExtraTreesClassifier(random_state=42, n_jobs=-1),\n",
    "    AdaBoostClassifier(random_state=42),\n",
    "    RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "    XGBClassifier(random_state=42),\n",
    "    LGBMClassifier(random_state=42)]\n",
    "                  \n",
    "print(\"Level 2 started\")\n",
    "\n",
    "def auc(y_true, y_pred):\n",
    "    \"\"\"ROC AUC metric for both binary and multiclass classification.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : 1d numpy array\n",
    "        True class labels\n",
    "    y_pred : 2d numpy array\n",
    "        Predicted probabilities for each class\n",
    "    \"\"\"\n",
    "    ohe = OneHotEncoder(sparse=False)\n",
    "    y_true = ohe.fit_transform(y_true.reshape(-1, 1))\n",
    "    auc_score = roc_auc_score(y_true, y_pred)\n",
    "    return auc_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [classification]\n",
      "n_classes:    [2]\n",
      "metric:       [auc]\n",
      "mode:         [oof_pred_bag]\n",
      "n_models:     [7]\n",
      "\n",
      "model  0:     [GaussianNB]\n",
      "    ----\n",
      "    MEAN:     [0.99145167] + [0.00028804]\n",
      "    FULL:     [0.99144905]\n",
      "\n",
      "model  1:     [LogisticRegression]\n",
      "    ----\n",
      "    MEAN:     [0.99782106] + [0.00011414]\n",
      "    FULL:     [0.99781695]\n",
      "\n",
      "model  2:     [ExtraTreesClassifier]\n",
      "    ----\n",
      "    MEAN:     [0.99521338] + [0.00037901]\n",
      "    FULL:     [0.99521134]\n",
      "\n",
      "model  3:     [AdaBoostClassifier]\n",
      "    ----\n",
      "    MEAN:     [0.99805635] + [0.00010451]\n",
      "    FULL:     [0.99804972]\n",
      "\n",
      "model  4:     [RandomForestClassifier]\n",
      "    ----\n",
      "    MEAN:     [0.99533305] + [0.00030219]\n",
      "    FULL:     [0.99533204]\n",
      "\n",
      "model  5:     [XGBClassifier]\n",
      "    ----\n",
      "    MEAN:     [0.99822596] + [0.00008584]\n",
      "    FULL:     [0.99822222]\n",
      "\n",
      "model  6:     [LGBMClassifier]\n",
      "    ----\n",
      "    MEAN:     [0.99812244] + [0.00012540]\n",
      "    FULL:     [0.99812081]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "S_tr, S_te = stacking(models,                     # list of models\n",
    "                           tr, train['target'], te,   # data\n",
    "                           regression=False,           # classification task (if you need \n",
    "                                                       #     regression - set to True)\n",
    "                           mode='oof_pred_bag',        # mode: oof for train set, predict test \n",
    "                                                       #     set in each fold and vote\n",
    "                           needs_proba=True,          # predict class labels (if you need \n",
    "                                                       #     probabilities - set to True) \n",
    "                           save_dir=None,              # do not save result and log (to save \n",
    "                                                       #     in current dir - set to '.')\n",
    "                           metric=auc,                 # metric: callable\n",
    "                           n_folds=10,                  # number of folds\n",
    "                           stratified=True,            # stratified split for folds\n",
    "                           shuffle=True,               # shuffle the data\n",
    "                           random_state=42,             # ensure reproducibility\n",
    "                           verbose=1)                  # print all info\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stack CV score = 0.96983\n"
     ]
    }
   ],
   "source": [
    "oof_lrr = np.zeros(len(train)) \n",
    "pred_te_lrr = np.zeros(len(test))\n",
    "skf = StratifiedKFold(n_splits=5, random_state=42)\n",
    "\n",
    "for train_index, test_index in skf.split(S_tr, train['target']):\n",
    "    lrr = linear_model.LogisticRegression()\n",
    "    lrr.fit(S_tr[train_index], train['target'][train_index])\n",
    "    oof_lrr[test_index] = lrr.predict_proba(S_tr[test_index,:])[:,1]\n",
    "    pred_te_lrr += lrr.predict_proba(S_te)[:,1] / skf.n_splits\n",
    "    \n",
    "print('stack CV score =',round(roc_auc_score(train_new['target'],oof_lrr),5))\n",
    "\n",
    "sub = pd.read_csv('../input/sample_submission.csv')\n",
    "\n",
    "#sub['target'] = pred_te_svnu*0.7 + pred_te_svc*0.05 + pred_te_knn*0.2 + pred_te_lr*0.05\n",
    "#sub.to_csv('submission_blend.csv', index=False)\n",
    "\n",
    "sub['target'] = pred_te_lrr\n",
    "sub.to_csv('submission_stack.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stack CV score l1 = 0.96997\n"
     ]
    }
   ],
   "source": [
    "oof_lrr = np.zeros(len(train)) \n",
    "pred_te_lrr = np.zeros(len(test))\n",
    "skf = StratifiedKFold(n_splits=5, random_state=42)\n",
    "\n",
    "for train_index, test_index in skf.split(tr, train['target']):\n",
    "    lrr = linear_model.LogisticRegression()\n",
    "    lrr.fit(tr[train_index], train['target'][train_index])\n",
    "    oof_lrr[test_index] = lrr.predict_proba(tr[test_index,:])[:,1]\n",
    "    pred_te_lrr += lrr.predict_proba(te)[:,1] / skf.n_splits\n",
    "    \n",
    "print('stack CV score l1 =',round(roc_auc_score(train_new['target'],oof_lrr),5))\n",
    "\n",
    "sub = pd.read_csv('../input/sample_submission.csv')\n",
    "\n",
    "sub['target'] = pred_te_lrr\n",
    "sub.to_csv('submission_stack_l1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
